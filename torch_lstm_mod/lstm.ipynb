{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an extendable implemtation of an LSTM, we'll use it as a starting point to investigate different structure\n",
    "\n",
    "Taken from here:  https://stackoverflow.com/questions/50168224/does-a-clean-and-extendable-lstm-implementation-exists-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.i2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = self._init_hidden(x)\n",
    "        \n",
    "        h, c = hidden\n",
    "        h = h.view(h.size(1), -1)\n",
    "        c = c.view(c.size(1), -1)\n",
    "        x = x.view(x.size(1), -1)\n",
    "\n",
    "        # Linear mappings\n",
    "        preact = self.i2h(x) + self.h2h(h)\n",
    "\n",
    "        # activations\n",
    "        gates = preact[:, :3 * self.hidden_size].sigmoid()\n",
    "        g_t = preact[:, 3 * self.hidden_size:].tanh()\n",
    "        i_t = gates[:, :self.hidden_size]\n",
    "        f_t = gates[:, self.hidden_size:2 * self.hidden_size]\n",
    "        o_t = gates[:, -self.hidden_size:]\n",
    "\n",
    "        c_t = th.mul(c, f_t) + th.mul(i_t, g_t)\n",
    "\n",
    "        h_t = th.mul(o_t, c_t.tanh())\n",
    "\n",
    "        #h_t = h_t.view(1, h_t.size(0), -1)\n",
    "        #c_t = c_t.view(1, c_t.size(0), -1)\n",
    "        return h_t, (h_t, c_t)\n",
    "\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_hidden(input_):\n",
    "        h = th.zeros_like(input_.view(1, input_.size(1), -1))\n",
    "        c = th.zeros_like(input_.view(1, input_.size(1), -1))\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.lstm_cell = LSTMCell(input_size, hidden_size, bias)\n",
    "\n",
    "    def forward(self, input_, hidden=None):\n",
    "        # input_ is of dimensionalty (1, time, input_size, ...)\n",
    "\n",
    "        outputs = []\n",
    "        for x in torch.unbind(input_, dim=1):\n",
    "            hidden = self.lstm_cell(x, hidden)\n",
    "            outputs.append(hidden[0].clone())\n",
    "\n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMCell(input_size = 4, hidden_size = 12, bias=False)\n",
    "\n",
    "x = th.randn(4,1)\n",
    "h = th.randn(12,1)\n",
    "c = th.randn(12,1)\n",
    "\n",
    "y, (ht, ct) = lstm.forward(x, (h,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(ht.shape)\n",
    "print(ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
