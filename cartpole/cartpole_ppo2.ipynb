{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sgillen/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /var/folders/qq/gpxz4l6s1tndfdhysbz8bdym0000gn/T/openai-2018-11-30-18-04-44-622709\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import multiprocessing\n",
    "import os.path as osp\n",
    "import gym\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from baselines.common.vec_env.vec_frame_stack import VecFrameStack\n",
    "from baselines.common.cmd_util import common_arg_parser, parse_unknown_args, make_vec_env\n",
    "from baselines.common.tf_util import get_session, load_variables\n",
    "from baselines import bench, logger\n",
    "from importlib import import_module\n",
    "\n",
    "from baselines.common.vec_env.vec_normalize import VecNormalize\n",
    "from baselines.common import atari_wrappers, retro_wrappers\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "except ImportError:\n",
    "    MPI = None\n",
    "\n",
    "try:\n",
    "    import pybullet_envs\n",
    "except ImportError:\n",
    "    pybullet_envs = None\n",
    "\n",
    "try:\n",
    "    import roboschool\n",
    "except ImportError:\n",
    "    roboschool = None\n",
    "\n",
    "_game_envs = defaultdict(set)\n",
    "for env in gym.envs.registry.all():\n",
    "    #print(env)\n",
    "    # TODO: solve this with regexes\n",
    "    env_type = env._entry_point.split(':')[0].split('.')[-1]\n",
    "    _game_envs[env_type].add(env.id)\n",
    "\n",
    "\"\"\"\n",
    "examples:\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=Robosimian-v2 --num_timesteps=0 --load_path=./models/robosimian_full_video --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=RobosimianIKTable-v2 --num_timesteps=0 --load_path=./models/robosimian_ik_2 --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=RobosimianIKTable-v2 --num_timesteps=0 --load_path=./models/FS_CS_50_rough_5mil --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=LeglessRobosimian-v2 --num_timesteps=0 --load_path=./models/robosimian_simple_4 --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=LeglessRobosimian3Wheels-v2 --num_timesteps=0 --load_path=./models/3_wheels --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=LeglessRobosimianXYZ-v2 --num_timesteps=1000000 --save_path=./models/simple_xyz_rough --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=RSBalance-v2 --num_timesteps=100000 --save_path=./models/balance_v0 --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=RSBalanceWithTraj-v2 --num_timesteps=100000 --save_path=./models/balance_with_traj_v0 --play\n",
    "\n",
    "python -m baselines.run --alg=ppo2 --env=RSBalanceWithTraj-v2 --num_timesteps=0 --load_path=./models/balance_with_traj_v1 --play\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#sys.exit()\n",
    "# reading benchmark names directly from retro requires\n",
    "# importing retro here, and for some reason that crashes tensorflow\n",
    "# in ubuntu\n",
    "_game_envs['retro'] = {\n",
    "    'BubbleBobble-Nes',\n",
    "    'SuperMarioBros-Nes',\n",
    "    'TwinBee3PokoPokoDaimaou-Nes',\n",
    "    'SpaceHarrier-Nes',\n",
    "    'SonicTheHedgehog-Genesis',\n",
    "    'Vectorman-Genesis',\n",
    "    'FinalFight-Snes',\n",
    "    'SpaceInvaders-Snes',\n",
    "}\n",
    "\n",
    "\n",
    "def train(args, extra_args):\n",
    "    env_type, env_id = get_env_type(args.env)\n",
    "    print('env_type: {}'.format(env_type))\n",
    "\n",
    "    total_timesteps = int(args.num_timesteps)\n",
    "    seed = args.seed\n",
    "\n",
    "    learn = get_learn_function(args.alg)\n",
    "    alg_kwargs = get_learn_function_defaults(args.alg, env_type)\n",
    "    alg_kwargs.update(extra_args)\n",
    "    #print(\"model defaults\",alg_kwargs)\n",
    "\n",
    "    env = build_env(args, alg_kwargs)\n",
    "\n",
    "    if args.network:\n",
    "        alg_kwargs['network'] = args.network\n",
    "    else:\n",
    "        if alg_kwargs.get('network') is None:\n",
    "            alg_kwargs['network'] = get_default_network(env_type)\n",
    "\n",
    "    print('Training {} on {}:{} with arguments \\n{}'.format(args.alg, env_type, env_id, alg_kwargs))\n",
    "\n",
    "    model = learn(\n",
    "        env=env,\n",
    "        seed=seed,\n",
    "        total_timesteps=total_timesteps,\n",
    "        **alg_kwargs\n",
    "    )\n",
    "\n",
    "    return model, env\n",
    "\n",
    "\n",
    "def build_env(args, alg_kwargs):\n",
    "    ncpu = multiprocessing.cpu_count()\n",
    "    if sys.platform == 'darwin': ncpu //= 2\n",
    "    nenv = args.num_env or ncpu\n",
    "    alg = args.alg\n",
    "    rank = MPI.COMM_WORLD.Get_rank() if MPI else 0\n",
    "    seed = args.seed\n",
    "\n",
    "    env_type, env_id = get_env_type(args.env)\n",
    "\n",
    "    if env_type == 'atari':\n",
    "        if alg == 'acer':\n",
    "            env = make_vec_env(env_id, env_type, nenv, seed)\n",
    "        elif alg == 'deepq':\n",
    "            env = atari_wrappers.make_atari(env_id)\n",
    "            env.seed(seed)\n",
    "            env = bench.Monitor(env, logger.get_dir())\n",
    "            env = atari_wrappers.wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "        elif alg == 'trpo_mpi':\n",
    "            env = atari_wrappers.make_atari(env_id)\n",
    "            env.seed(seed)\n",
    "            env = bench.Monitor(env, logger.get_dir() and osp.join(logger.get_dir(), str(rank)))\n",
    "            env = atari_wrappers.wrap_deepmind(env)\n",
    "            # TODO check if the second seeding is necessary, and eventually remove\n",
    "            env.seed(seed)\n",
    "        else:\n",
    "            frame_stack_size = 4\n",
    "            env = VecFrameStack(make_vec_env(env_id, env_type, nenv, seed), frame_stack_size)\n",
    "\n",
    "    elif env_type == 'retro':\n",
    "        import retro\n",
    "        gamestate = args.gamestate or 'Level1-1'\n",
    "        env = retro_wrappers.make_retro(game=args.env, state=gamestate, max_episode_steps=10000,\n",
    "                                        use_restricted_actions=retro.Actions.DISCRETE)\n",
    "        env.seed(args.seed)\n",
    "        env = bench.Monitor(env, logger.get_dir())\n",
    "        env = retro_wrappers.wrap_deepmind_retro(env)\n",
    "\n",
    "    else: \n",
    "        get_session(tf.ConfigProto(allow_soft_placement=True,\n",
    "                                   intra_op_parallelism_threads=1,\n",
    "                                   inter_op_parallelism_threads=1))\n",
    "\n",
    "        env = make_vec_env(env_id, env_type, args.num_env or 1, seed, reward_scale=args.reward_scale)\n",
    "\n",
    "        if env_type == 'mujoco':\n",
    "            env = VecNormalize(env)\n",
    "            if alg_kwargs.get('load_path'):\n",
    "                sess = get_session()\n",
    "                loaded_params = joblib.load(osp.expanduser(alg_kwargs['load_path']))\n",
    "                restores = []\n",
    "                for v in tf.trainable_variables():\n",
    "                    restores.append(v.assign(loaded_params[v.name]))\n",
    "                sess.run(restores)\n",
    "\n",
    "                \"\"\" THIS IS NECESSARY TO UPDATE the .mean, .count vars.. otherwise it is still confused!!!!!!! THANKS A LOT OPENAI\"\"\"\n",
    "                env.ob_rms._set_mean_var_count()\n",
    "                env.ret_rms._set_mean_var_count()\n",
    "                #print(dir(env.ret_rms))\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "def get_env_type(env_id):\n",
    "    if env_id in _game_envs.keys():\n",
    "        env_type = env_id\n",
    "        env_id = [g for g in _game_envs[env_type]][0]\n",
    "    else:\n",
    "        env_type = None\n",
    "        for g, e in _game_envs.items():\n",
    "            if env_id in e:\n",
    "                env_type = g\n",
    "                break\n",
    "        assert env_type is not None, 'env_id {} is not recognized in env types'.format(env_id, _game_envs.keys())\n",
    "\n",
    "    return env_type, env_id\n",
    "\n",
    "\n",
    "def get_default_network(env_type):\n",
    "    if env_type == 'atari':\n",
    "        return 'cnn'\n",
    "    else:\n",
    "        return 'mlp'\n",
    "\n",
    "    raise ValueError('Unknown env_type {}'.format(env_type))\n",
    "\n",
    "\n",
    "def get_alg_module(alg, submodule=None):\n",
    "    submodule = submodule or alg\n",
    "    try:\n",
    "        # first try to import the alg module from baselines\n",
    "        alg_module = import_module('.'.join(['baselines', alg, submodule]))\n",
    "    except ImportError:\n",
    "        # then from rl_algs\n",
    "        alg_module = import_module('.'.join(['rl_' + 'algs', alg, submodule]))\n",
    "\n",
    "    return alg_module\n",
    "\n",
    "\n",
    "def get_learn_function(alg):\n",
    "    return get_alg_module(alg).learn\n",
    "\n",
    "\n",
    "def get_learn_function_defaults(alg, env_type):\n",
    "    try:\n",
    "        alg_defaults = get_alg_module(alg, 'defaults')\n",
    "        kwargs = getattr(alg_defaults, env_type)()\n",
    "    except (ImportError, AttributeError):\n",
    "        kwargs = {}\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def parse(v):\n",
    "    '''\n",
    "    convert value of a command-line arg to a python object if possible, othewise, keep as string\n",
    "    '''\n",
    "\n",
    "    assert isinstance(v, str)\n",
    "    try:\n",
    "        return eval(v)\n",
    "    except (NameError, SyntaxError):\n",
    "        return v\n",
    "\n",
    "\n",
    "def main():\n",
    "    # configure logger, disable logging in child MPI processes (with rank > 0)\n",
    "    arg_parser = common_arg_parser()\n",
    "    args, unknown_args = arg_parser.parse_known_args()\n",
    "    extra_args = {k: parse(v) for k, v in parse_unknown_args(unknown_args).items()}\n",
    "\n",
    "    # print(MPI, MPI.COMM_WORLD.Get_rank())\n",
    "    # sys.exit()\n",
    "\n",
    "    if MPI is None or MPI.COMM_WORLD.Get_rank() == 0:\n",
    "        rank = 0\n",
    "        logger.configure()\n",
    "        #logger.configure(dir=\"./logging_dir/\")\n",
    "    else:\n",
    "        logger.configure(format_strs=[])\n",
    "        rank = MPI.COMM_WORLD.Get_rank()\n",
    "\n",
    "    #with tf.Session(graph=tf.Graph()):\n",
    "    model, env = train(args, extra_args)\n",
    "\n",
    "    print(env.ob_rms.mean)\n",
    "\n",
    "    if args.save_path is not None and rank == 0:\n",
    "        save_path = osp.expanduser(args.save_path)\n",
    "        model.save(save_path)\n",
    "\n",
    "    if args.play:\n",
    "        logger.log(\"Running trained model\")\n",
    "        obs = env.reset()\n",
    "        #print(\"\\n IK table... \")\n",
    "\n",
    "        doneCounter = 0\n",
    "        num_runs = 100\n",
    "\n",
    "        while doneCounter < num_runs:\n",
    "            actions, v, state, neglogp = model.step(obs)\n",
    "            obs, rewards, done, infos = env.step(actions)\n",
    "            done = done.any() if isinstance(done, np.ndarray) else done\n",
    "\n",
    "            if done:\n",
    "                print(doneCounter, \"done\", infos)\n",
    "                infos = infos[0]\n",
    "\n",
    "                obs = env.reset()\n",
    "                doneCounter +=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
